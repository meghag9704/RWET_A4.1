{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9338ea50",
   "metadata": {},
   "source": [
    "### Revisiting the Digital Text Cut-Up. \n",
    "\n",
    "Most of this is word-for-word code and examples and step-by-step processes from Allison's SpaCy introduction notebook. (https://github.com/aparrish/rwet/blob/master/nlp-concepts-with-spacy.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fbd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd8d32",
   "metadata": {},
   "source": [
    "Importing Tracery, SpaCy, MatPlotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23415e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tracery in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (0.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tracery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa07b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926fd4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install -c conda-forge -y --prefix {sys.prefix} spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fd0dfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from en-core-web-md==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: setuptools in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (63.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (21.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.21.5)\n",
      "Requirement already satisfied: jinja2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.9.24)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/meghagoel/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad002ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573aa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from textwrap import fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c5633ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "'Pattern matched multiple keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2n/_0wc0zb96nlb_gcsfwr89gc00000gn/T/ipykernel_65363/3745183971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ggplot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"figure.figsize\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_set_option\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_single_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_registered_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No such keys(s): {repr(pat)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pattern matched multiple keys\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOptionError\u001b[0m: 'Pattern matched multiple keys'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_rows', 25)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073446a",
   "metadata": {},
   "source": [
    "I think I've imported all the relevant system requirements and requirements for SpaCy and Tracery. But I am also realizing that I could have done this later. Either way it's now out of the way. \n",
    "\n",
    "> **For some reason that I am unable to find the above matplotlib import didn't work. I think theimport worked but setting the number of rows is not working.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c6290",
   "metadata": {},
   "source": [
    "### Now time to import the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ecc02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My brain won’t accept it but things have changed. \n",
      "You have changed and my brain won’t accept it.\n",
      "I have changed and my brain won’t accept it. \n",
      "I look out into the mirror and see the same brown eyes \n",
      "But they are a little bit darker\n",
      "A little bit shrouded\n",
      "With a fire resembling fear \n",
      "And the thirst quenched with answers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = open(\"jan_2018.txt\").read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e6f7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca4cefe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)\n",
    "words = [w for w in list(doc) if w.is_alpha]\n",
    "noun_chunks = list(doc.noun_chunks)\n",
    "entities = list(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c87dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[My brain won’t accept it but things have changed. \n",
      ", You have changed and my brain won’t accept it.\n",
      ", I have changed and my brain won’t accept it. \n",
      ", I look out into the mirror and see the same brown eyes \n",
      ", But they are a little bit darker\n",
      "A little bit shrouded\n",
      "With a fire resembling fear \n",
      "And the thirst quenched with answers\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "613f8a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[My, brain, wo, accept, it, but, things, have, changed, You, have, changed, and, my, brain, wo, accept, it, I, have, changed, and, my, brain, wo, accept, it, I, look, out, into, the, mirror, and, see, the, same, brown, eyes, But, they, are, a, little, bit, darker, A, little, bit, shrouded, With, a, fire, resembling, fear, And, the, thirst, quenched, with, answers]\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017f138",
   "metadata": {},
   "source": [
    "Noticing that words could not compensate for apostrophe words. \n",
    "\"won't\" became \"wo\" \"nt\" is lost and not part of the words list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f99832b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[My brain, it, things, You, my brain, it, I, my brain, it, I, the mirror, the same brown eyes, they, a fire, the thirst, answers]\n"
     ]
    }
   ],
   "source": [
    "print(noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1afef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee534f2",
   "metadata": {},
   "source": [
    "Indentifying that there aren't any entities in this text-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0540e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [w for w in words if w.pos_ == \"NOUN\"]\n",
    "verbs = [w for w in words if w.pos_ == \"VERB\"]\n",
    "adjs = [w for w in words if w.pos_ == \"ADJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e5e6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[brain, things, brain, brain, mirror, eyes, bit, bit, fire, fear, thirst, answers]\n"
     ]
    }
   ],
   "source": [
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edc1e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accept, changed, changed, accept, changed, accept, look, see, shrouded, resembling, quenched]\n"
     ]
    }
   ],
   "source": [
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf48d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[same, brown, little, darker, little]\n"
     ]
    }
   ],
   "source": [
    "print(adjs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869e595",
   "metadata": {},
   "source": [
    "Splitting words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "967e7098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'brain', 'won’t', 'accept', 'it', 'but', 'things', 'have', 'changed.', '\\nYou', 'have', 'changed', 'and', 'my', 'brain', 'won’t', 'accept', 'it.\\nI', 'have', 'changed', 'and', 'my', 'brain', 'won’t', 'accept', 'it.', '\\nI', 'look', 'out', 'into', 'the', 'mirror', 'and', 'see', 'the', 'same', 'brown', 'eyes', '\\nBut', 'they', 'are', 'a', 'little', 'bit', 'darker\\nA', 'little', 'bit', 'shrouded\\nWith', 'a', 'fire', 'resembling', 'fear', '\\nAnd', 'the', 'thirst', 'quenched', 'with', 'answers\\n']\n"
     ]
    }
   ],
   "source": [
    "words_space = text.split(\" \")\n",
    "print(words_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "401248cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My -> my\n",
      "brain -> brain\n",
      "wo -> will\n",
      "accept -> accept\n",
      "it -> it\n",
      "but -> but\n",
      "things -> thing\n",
      "have -> have\n",
      "changed -> change\n",
      "You -> you\n",
      "have -> have\n",
      "changed -> change\n",
      "and -> and\n",
      "my -> my\n",
      "brain -> brain\n",
      "wo -> will\n",
      "accept -> accept\n",
      "it -> it\n",
      "I -> I\n",
      "have -> have\n",
      "changed -> change\n",
      "and -> and\n",
      "my -> my\n",
      "brain -> brain\n",
      "wo -> will\n",
      "accept -> accept\n",
      "it -> it\n",
      "I -> I\n",
      "look -> look\n",
      "out -> out\n",
      "into -> into\n",
      "the -> the\n",
      "mirror -> mirror\n",
      "and -> and\n",
      "see -> see\n",
      "the -> the\n",
      "same -> same\n",
      "brown -> brown\n",
      "eyes -> eye\n",
      "But -> but\n",
      "they -> they\n",
      "are -> be\n",
      "a -> a\n",
      "little -> little\n",
      "bit -> bit\n",
      "darker -> dark\n",
      "A -> a\n",
      "little -> little\n",
      "bit -> bit\n",
      "shrouded -> shroud\n",
      "With -> with\n",
      "a -> a\n",
      "fire -> fire\n",
      "resembling -> resemble\n",
      "fear -> fear\n",
      "And -> and\n",
      "the -> the\n",
      "thirst -> thirst\n",
      "quenched -> quench\n",
      "with -> with\n",
      "answers -> answer\n"
     ]
    }
   ],
   "source": [
    "for word in words: \n",
    "    print(word.text, \"->\", word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f5f92b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'brain', 'will', 'accept', 'it', 'but', 'thing', 'have', 'change', 'you', 'have', 'change', 'and', 'my', 'brain', 'will', 'accept', 'it', 'I', 'have', 'change', 'and', 'my', 'brain', 'will', 'accept', 'it', 'I', 'look', 'out', 'into', 'the', 'mirror', 'and', 'see', 'the', 'same', 'brown', 'eye', 'but', 'they', 'be', 'a', 'little', 'bit', 'dark', 'a', 'little', 'bit', 'shroud', 'with', 'a', 'fire', 'resemble', 'fear', 'and', 'the', 'thirst', 'quench', 'with', 'answer']\n"
     ]
    }
   ],
   "source": [
    "basicWord = [w.lemma_ for w in words]\n",
    "print(basicWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f27418",
   "metadata": {},
   "source": [
    "Filter words and basicWords for  unique words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71982747",
   "metadata": {},
   "outputs": [],
   "source": [
    "uWords = [*set(words)]\n",
    "uBasic = [*set(basicWord)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0873cb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[the, brown, see, But, a, little, darker, My, but, fire, thirst, changed, and, answers, You, wo, it, and, I, wo, it, into, I, and, same, are, bit, shrouded, A, a, wo, have, fear, it, with, the, changed, accept, brain, changed, accept, brain, mirror, out, the, eyes, little, they, brain, bit, resembling, accept, With, And, things, have, quenched, my, have, my, look]\n",
      "['answer', 'see', 'I', 'same', 'brain', 'thing', 'and', 'you', 'resemble', 'be', 'will', 'fear', 'mirror', 'bit', 'with', 'look', 'shroud', 'little', 'accept', 'brown', 'a', 'it', 'dark', 'fire', 'thirst', 'have', 'into', 'out', 'they', 'but', 'the', 'change', 'eye', 'quench', 'my']\n"
     ]
    }
   ],
   "source": [
    "print(uWords)\n",
    "print(uBasic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd9b05b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2n/_0wc0zb96nlb_gcsfwr89gc00000gn/T/ipykernel_65363/1536042826.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muBasic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "for item in uBasic:\n",
    "    print(item.text, \"/\", item.pos_, \"/\", item.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa5c15",
   "metadata": {},
   "source": [
    "Realizing that the above does not have a tag or part of speech because these haven't been used in a sentence. they are the basic words and the conversions of the words. \n",
    "\n",
    "Interesting how \"wo\" which was the shortened and recognized part of \"won't\" was recognized as \"will\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f1dfa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the / DET / DT\n",
      "brown / ADJ / JJ\n",
      "see / VERB / VB\n",
      "But / CCONJ / CC\n",
      "a / DET / DT\n",
      "little / ADJ / JJ\n",
      "darker / ADJ / JJR\n",
      "My / PRON / PRP$\n",
      "but / CCONJ / CC\n",
      "fire / NOUN / NN\n",
      "thirst / NOUN / NN\n",
      "changed / VERB / VBN\n",
      "and / CCONJ / CC\n",
      "answers / NOUN / NNS\n",
      "You / PRON / PRP\n",
      "wo / AUX / MD\n",
      "it / PRON / PRP\n",
      "and / CCONJ / CC\n",
      "I / PRON / PRP\n",
      "wo / AUX / MD\n",
      "it / PRON / PRP\n",
      "into / ADP / IN\n",
      "I / PRON / PRP\n",
      "and / CCONJ / CC\n",
      "same / ADJ / JJ\n",
      "are / AUX / VBP\n",
      "bit / NOUN / NN\n",
      "shrouded / VERB / VBD\n",
      "A / DET / DT\n",
      "a / DET / DT\n",
      "wo / AUX / MD\n",
      "have / AUX / VBP\n",
      "fear / NOUN / NN\n",
      "it / PRON / PRP\n",
      "with / ADP / IN\n",
      "the / DET / DT\n",
      "changed / VERB / VBN\n",
      "accept / VERB / VB\n",
      "brain / NOUN / NN\n",
      "changed / VERB / VBN\n",
      "accept / VERB / VB\n",
      "brain / NOUN / NN\n",
      "mirror / NOUN / NN\n",
      "out / ADP / RP\n",
      "the / DET / DT\n",
      "eyes / NOUN / NNS\n",
      "little / ADJ / JJ\n",
      "they / PRON / PRP\n",
      "brain / NOUN / NN\n",
      "bit / NOUN / NN\n",
      "resembling / VERB / VBG\n",
      "accept / VERB / VB\n",
      "With / ADP / IN\n",
      "And / CCONJ / CC\n",
      "things / NOUN / NNS\n",
      "have / AUX / VBP\n",
      "quenched / VERB / VBD\n",
      "my / PRON / PRP$\n",
      "have / AUX / VBP\n",
      "my / PRON / PRP$\n",
      "look / VERB / VBP\n"
     ]
    }
   ],
   "source": [
    "for item in uWords: \n",
    "    print(item.text, \"/\", item.pos_, \"/\", item.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2a04add",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'spacy.tokens.span.Span'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2n/_0wc0zb96nlb_gcsfwr89gc00000gn/T/ipykernel_65363/265390194.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;31m#call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m         \"\"\"\n\u001b[0;32m--> 999\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m_ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE1041\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     def _ensure_doc_with_context(\n",
      "\u001b[0;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'spacy.tokens.span.Span'>"
     ]
    }
   ],
   "source": [
    "spacy.displacy.render(nlp(random.choice(sentences)), style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14e7c4",
   "metadata": {},
   "source": [
    "> **Not sure what happened above or what that code is meant to do**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e458f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But they are a little bit darker\n",
      "A little bit shrouded\n",
      "With a fire resembling fear \n",
      "And the thirst quenched with answers\n",
      "\n",
      "\n",
      "Word: But\n",
      "Basic: but\n",
      "Tag: CC\n",
      "Head: are\n",
      "Dependency relation: cc\n",
      "Children: []\n",
      "\n",
      "Word: they\n",
      "Basic: they\n",
      "Tag: PRP\n",
      "Head: are\n",
      "Dependency relation: nsubj\n",
      "Children: []\n",
      "\n",
      "Word: are\n",
      "Basic: be\n",
      "Tag: VBP\n",
      "Head: are\n",
      "Dependency relation: ROOT\n",
      "Children: [But, they, darker, fear, And, quenched]\n",
      "\n",
      "Word: a\n",
      "Basic: a\n",
      "Tag: DT\n",
      "Head: bit\n",
      "Dependency relation: det\n",
      "Children: []\n",
      "\n",
      "Word: little\n",
      "Basic: little\n",
      "Tag: JJ\n",
      "Head: bit\n",
      "Dependency relation: amod\n",
      "Children: []\n",
      "\n",
      "Word: bit\n",
      "Basic: bit\n",
      "Tag: NN\n",
      "Head: darker\n",
      "Dependency relation: npadvmod\n",
      "Children: [a, little]\n",
      "\n",
      "Word: darker\n",
      "Basic: dark\n",
      "Tag: JJR\n",
      "Head: are\n",
      "Dependency relation: acomp\n",
      "Children: [bit, \n",
      "]\n",
      "\n",
      "Word: \n",
      "\n",
      "Basic: \n",
      "\n",
      "Tag: _SP\n",
      "Head: darker\n",
      "Dependency relation: dep\n",
      "Children: []\n",
      "\n",
      "Word: A\n",
      "Basic: a\n",
      "Tag: DT\n",
      "Head: bit\n",
      "Dependency relation: det\n",
      "Children: []\n",
      "\n",
      "Word: little\n",
      "Basic: little\n",
      "Tag: JJ\n",
      "Head: bit\n",
      "Dependency relation: amod\n",
      "Children: []\n",
      "\n",
      "Word: bit\n",
      "Basic: bit\n",
      "Tag: NN\n",
      "Head: shrouded\n",
      "Dependency relation: npadvmod\n",
      "Children: [A, little]\n",
      "\n",
      "Word: shrouded\n",
      "Basic: shroud\n",
      "Tag: VBD\n",
      "Head: fear\n",
      "Dependency relation: amod\n",
      "Children: [bit, \n",
      ", With]\n",
      "\n",
      "Word: \n",
      "\n",
      "Basic: \n",
      "\n",
      "Tag: _SP\n",
      "Head: shrouded\n",
      "Dependency relation: dep\n",
      "Children: []\n",
      "\n",
      "Word: With\n",
      "Basic: with\n",
      "Tag: IN\n",
      "Head: shrouded\n",
      "Dependency relation: prep\n",
      "Children: [fire]\n",
      "\n",
      "Word: a\n",
      "Basic: a\n",
      "Tag: DT\n",
      "Head: fire\n",
      "Dependency relation: det\n",
      "Children: []\n",
      "\n",
      "Word: fire\n",
      "Basic: fire\n",
      "Tag: NN\n",
      "Head: With\n",
      "Dependency relation: pobj\n",
      "Children: [a]\n",
      "\n",
      "Word: resembling\n",
      "Basic: resemble\n",
      "Tag: VBG\n",
      "Head: fear\n",
      "Dependency relation: amod\n",
      "Children: []\n",
      "\n",
      "Word: fear\n",
      "Basic: fear\n",
      "Tag: NN\n",
      "Head: are\n",
      "Dependency relation: attr\n",
      "Children: [shrouded, resembling, \n",
      "]\n",
      "\n",
      "Word: \n",
      "\n",
      "Basic: \n",
      "\n",
      "Tag: _SP\n",
      "Head: fear\n",
      "Dependency relation: dep\n",
      "Children: []\n",
      "\n",
      "Word: And\n",
      "Basic: and\n",
      "Tag: CC\n",
      "Head: are\n",
      "Dependency relation: cc\n",
      "Children: []\n",
      "\n",
      "Word: the\n",
      "Basic: the\n",
      "Tag: DT\n",
      "Head: thirst\n",
      "Dependency relation: det\n",
      "Children: []\n",
      "\n",
      "Word: thirst\n",
      "Basic: thirst\n",
      "Tag: NN\n",
      "Head: quenched\n",
      "Dependency relation: nsubj\n",
      "Children: [the]\n",
      "\n",
      "Word: quenched\n",
      "Basic: quench\n",
      "Tag: VBD\n",
      "Head: are\n",
      "Dependency relation: conj\n",
      "Children: [thirst, with]\n",
      "\n",
      "Word: with\n",
      "Basic: with\n",
      "Tag: IN\n",
      "Head: quenched\n",
      "Dependency relation: prep\n",
      "Children: [answers]\n",
      "\n",
      "Word: answers\n",
      "Basic: answer\n",
      "Tag: NNS\n",
      "Head: with\n",
      "Dependency relation: pobj\n",
      "Children: [\n",
      "]\n",
      "\n",
      "Word: \n",
      "\n",
      "Basic: \n",
      "\n",
      "Tag: _SP\n",
      "Head: answers\n",
      "Dependency relation: dep\n",
      "Children: []\n"
     ]
    }
   ],
   "source": [
    "sent = random.choice(sentences)\n",
    "print(sent)\n",
    "for word in sent: \n",
    "    print()\n",
    "    print(\"Word:\", word.text)\n",
    "    print(\"Basic:\", word.lemma_)\n",
    "    print(\"Tag:\", word.tag_)\n",
    "    print(\"Head:\", word.head.text)\n",
    "    print(\"Dependency relation:\", word.dep_)\n",
    "    print(\"Children:\", list(word.children))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d773277",
   "metadata": {},
   "source": [
    "Recognizing that the sentence is more than just the line. It is not recognizing the line break as the end of a sentence in poetry. It is waiting for the fullstop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91a55828",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "for word in uWords:\n",
    "    if word.dep_ in ('nsubj', 'nsubjpass'):\n",
    "        subjects.append(flatten_subtree(word.subtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c09915fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the thirst', 'You', 'I', 'I', 'my brain', 'my brain', 'they', 'My brain', 'things']\n"
     ]
    }
   ],
   "source": [
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a3c52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_subtree(st): \n",
    "    return ''.join([w.text_with_ws for w in list(st)]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d7c3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_phrases = []\n",
    "for word in uWords:\n",
    "    if word.dep_ == 'prep':\n",
    "        prep_phrases.append(flatten_subtree(word.subtree).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d979afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['into the mirror', 'with answers', 'With a fire']\n"
     ]
    }
   ],
   "source": [
    "print(prep_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875bc9c1",
   "metadata": {},
   "source": [
    "#### Manipulating the text to create the digital text cut-up. \n",
    "Continuation from Allison's SpaCy introduction notebook. (linked above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c382c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [flatten_subtree(word.subtree).replace(\"\\n\", \" \")\n",
    "            for word in doc if word.dep_ in ('nsubj', 'nsubjpass')]\n",
    "past_tense_verbs = [word.text for word in uWords if word.tag_ == 'VBD' and word.lemma_ != 'be']\n",
    "adjectives = [word.text for word in uWords if word.tag_.startswith('JJ')]\n",
    "nouns = [word.text for word in uWords if word.tag_.startswith('NN')]\n",
    "prep_phrases = [flatten_subtree(word.subtree).replace(\"\\n\", \" \")\n",
    "                for word in doc if word.dep_ == 'prep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b5ecb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My brain', 'things', 'You', 'my brain', 'I', 'my brain', 'I', 'they', 'the thirst']\n"
     ]
    }
   ],
   "source": [
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cfbe5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shrouded', 'quenched']\n"
     ]
    }
   ],
   "source": [
    "print(past_tense_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1e627ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown', 'little', 'darker', 'same', 'little']\n"
     ]
    }
   ],
   "source": [
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1dd277a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fire', 'thirst', 'answers', 'bit', 'fear', 'brain', 'brain', 'mirror', 'eyes', 'brain', 'bit', 'things']\n"
     ]
    }
   ],
   "source": [
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85aaf315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['into the mirror', 'With a fire', 'with answers']\n"
     ]
    }
   ],
   "source": [
    "print(prep_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21aeebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With answers, my brain shrouded the brain and the fire.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": [\n",
    "        \"#subject.capitalize# #predicate#.\",\n",
    "        \"#subject.capitalize# #predicate#.\",\n",
    "        \"#prepphrase.capitalize#, #subject# #predicate#.\"\n",
    "    ],\n",
    "    \"predicate\": [\n",
    "        \"#verb#\",\n",
    "        \"#verb# #nounphrase#\",\n",
    "        \"#verb# #prepphrase#\"\n",
    "    ],\n",
    "    \"nounphrase\": [\n",
    "        \"the #noun#\",\n",
    "        \"the #adj# #noun#\",\n",
    "        \"the #noun# #prepphrase#\",\n",
    "        \"the #noun# and the #noun#\",\n",
    "        \"#noun.a#\",\n",
    "        \"#adj.a# #noun#\",\n",
    "        \"the #noun# that #predicate#\"\n",
    "    ],\n",
    "    \"subject\": subjects,\n",
    "    \"verb\": past_tense_verbs,\n",
    "    \"noun\": nouns,\n",
    "    \"adj\": adjectives,\n",
    "    \"prepphrase\": prep_phrases\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e4506d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I quenched. With a fire, I shrouded. With a fire, I quenched\n",
      "With a fire. Into the mirror, my brain quenched. With\n",
      "answers, My brain quenched With a fire. Things quenched. You\n",
      "shrouded. They quenched. I shrouded. My brain shrouded With\n",
      "a fire. With a fire, the thirst shrouded the brain that\n",
      "shrouded the bit that shrouded. With answers, my brain\n",
      "shrouded.\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "output = \" \".join([grammar.flatten(\"#origin#\") for i in range(12)])\n",
    "print(fill(output, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f400fd",
   "metadata": {},
   "source": [
    "## Making the digital cut-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rules = {\n",
    "    \"origin\": [\n",
    "        \"#subject.capitalize# #predicate#.\",\n",
    "        \"#noun.capitalize# #nounphrase# #predicate#.\",\n",
    "        \"#verb.capitalize#, #subject# #predicate#.\",\n",
    "        \"#verb.capitalize# #adj# #noun# #adj# #prepphrase#\"\n",
    "    ],\n",
    "    \"predicate\": [\n",
    "        \"#verb#\",\n",
    "        \"#verb# #nounphrase#\",\n",
    "        \"#verb# #prepphrase#\"\n",
    "    ],\n",
    "    \"nounphrase\": [\n",
    "        \"the #noun#\",\n",
    "        \"the #adj# #noun#\",\n",
    "        \"the #noun# #prepphrase#\",\n",
    "        \"the #noun# and the #noun#\",\n",
    "        \"#noun.a#\",\n",
    "        \"#adj.a# #noun#\",\n",
    "        \"the #noun# that #predicate#\"\n",
    "    ],\n",
    "    \"subject\": subjects,\n",
    "    \"verb\": past_tense_verbs,\n",
    "    \"noun\": nouns,\n",
    "    \"adj\": adjectives,\n",
    "    \"prepphrase\": prep_phrases\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3ddd994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain quenched things same With a fire\n",
      "Brain quenched My brain brown with answers\n",
      "Bit shrouded You same into the mirror\n",
      "Bit quenched I little into the mirror\n",
      "Eyes shrouded the thirst same with answers\n",
      "Brain shrouded My brain little with answers\n",
      "Bit quenched I darker with answers\n",
      "Fire quenched my brain little with answers\n",
      "Fire quenched You little into the mirror\n",
      "Eyes shrouded I little into the mirror\n"
     ]
    }
   ],
   "source": [
    "final_rules= { \n",
    "    \"origin\": \"#noun.capitalize# #verb# #subject# #adj# #prepphrase#\",\n",
    "    \"noun\": nouns, \n",
    "    \"verb\": past_tense_verbs,\n",
    "    \"adj\": adjectives,\n",
    "    \"subject\": subjects,\n",
    "    \"prepphrase\": prep_phrases\n",
    "}\n",
    "final_grammar = tracery.Grammar(final_rules)\n",
    "final_grammar.add_modifiers(base_english)\n",
    "for i in range(10): \n",
    "    print(final_grammar.flatten(\"#origin#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "589d9b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eyes quenched my brain darker with answers\n",
      "Things quenched I darker With a fire\n",
      "Brain shrouded the thirst same With a fire\n",
      "Brain quenched they little with answers\n",
      "Eyes shrouded I little with answers\n",
      "Fear quenched the thirst darker into the mirror\n",
      "Bit shrouded the thirst little into the mirror\n",
      "Things quenched My brain little with answers\n",
      "Thirst quenched my brain little with answers\n",
      "Eyes quenched You darker into the mirror\n"
     ]
    }
   ],
   "source": [
    "final_rules= { \n",
    "    \"origin\": \"#noun.capitalize# #verb# #subject# #adj# #prepphrase#\",\n",
    "    \"noun\": nouns, \n",
    "    \"verb\": past_tense_verbs,\n",
    "    \"adj\": adjectives,\n",
    "    \"subject\": subjects,\n",
    "    \"prepphrase\": prep_phrases\n",
    "}\n",
    "final_grammar = tracery.Grammar(final_rules)\n",
    "final_grammar.add_modifiers(base_english)\n",
    "for i in range(10): \n",
    "    print(final_grammar.flatten(\"#origin#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ac833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bafb673",
   "metadata": {},
   "source": [
    "---\n",
    "### This is code from the previous digital text cut-up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50284dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'things'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(words)\n",
    "short_words = [item for item in words if len(item) < 5 and len(item) > 0]\n",
    "long_words = [item for item in words if len(item) > 5]\n",
    "lines = text.split(\"\\n\")\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31cbeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My brain won’t accept it but things have changed. ', 'You have changed and my brain won’t accept it.', 'I have changed and my brain won’t accept it. ', 'I look out into the mirror and see the same brown eyes ', 'But they are a little bit darker', 'A little bit shrouded', 'With a fire resembling fear ', 'And the thirst quenched with answers', '']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8bdc210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have changed and my brain won’t accept it.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(lines)\n",
    "random.choice(words) + random.choice(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "382389b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it changed\n",
      "I answers\n",
      "With shrouded\n",
      "into quenched\n",
      "have changed.\n",
      "A accept\n",
      "it accept\n",
      "into darker\n",
      "bit accept\n",
      "into shrouded\n"
     ]
    }
   ],
   "source": [
    "# short words + long words\n",
    "for i in range(10):\n",
    "    print(random.choice(short_words) + \" \" + random.choice(long_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f254218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have accept changed A\n",
      "a mirror things With\n",
      "I little little my\n",
      "A things answers same\n",
      "I answers resembling out\n",
      "My things accept And\n",
      "the answers little My\n",
      "fire accept thirst and\n",
      "same changed thirst the\n",
      "and quenched changed and\n"
     ]
    }
   ],
   "source": [
    "#  short words + long words + long words + short words\n",
    "for i in range(10):\n",
    "    print(random.choice(short_words) + \" \" + random.choice(long_words) + \" \" + random.choice(long_words) + \" \" + random.choice(short_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a4ccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(words)):\n",
    "    words[i] = words[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ad22de",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = [*set(words)] #https://www.geeksforgeeks.org/python-ways-to-remove-duplicates-from-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ce798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(unique_words, 3)\n",
    "new_sent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93036899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i with brain\n",
      "darker brown resembling\n",
      "with out darker\n",
      "changed. and a\n",
      "resembling answers eyes\n",
      "brain a and\n",
      "changed into fear\n",
      "and my the\n",
      "fire changed. look\n",
      "changed it. darker\n"
     ]
    }
   ],
   "source": [
    "glue = \" \"\n",
    "for i in range(10):\n",
    "    a = random.sample(unique_words, 3)\n",
    "    new_sent.append(glue.join(a))\n",
    "    print(glue.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "321bb684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['won’t fire shrouded',\n",
       " 'it. fire changed.',\n",
       " 'brain a changed',\n",
       " 'it. darker brown',\n",
       " 'won’t my look',\n",
       " 'same thirst fear',\n",
       " 'quenched answers same',\n",
       " 'a out little',\n",
       " 'same accept and',\n",
       " 'they my eyes',\n",
       " 'shrouded fear things',\n",
       " 'won’t they shrouded',\n",
       " 'i won’t fear',\n",
       " 'answers i quenched',\n",
       " 'are eyes out',\n",
       " 'have my fire',\n",
       " 'accept bit it',\n",
       " 'but changed the',\n",
       " 'my have are',\n",
       " 'accept eyes are',\n",
       " 'it. see fire',\n",
       " 'i changed answers',\n",
       " 'little bit mirror',\n",
       " 'won’t they but',\n",
       " 'you look eyes',\n",
       " 'changed eyes fire',\n",
       " 'my but with',\n",
       " 'they darker brown',\n",
       " 'accept my darker',\n",
       " 'fear my look',\n",
       " 'i with brain',\n",
       " 'darker brown resembling',\n",
       " 'with out darker',\n",
       " 'changed. and a',\n",
       " 'resembling answers eyes',\n",
       " 'brain a and',\n",
       " 'changed into fear',\n",
       " 'and my the',\n",
       " 'fire changed. look',\n",
       " 'changed it. darker']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fdf6f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_new_sent = [*set(new_sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9af28306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i won’t fear',\n",
       " 'changed. and a',\n",
       " 'it. see fire',\n",
       " 'a out little',\n",
       " 'are eyes out',\n",
       " 'you look eyes',\n",
       " 'fear my look',\n",
       " 'and my the',\n",
       " 'won’t my look',\n",
       " 'my but with',\n",
       " 'accept bit it',\n",
       " 'they my eyes',\n",
       " 'won’t they but',\n",
       " 'i with brain',\n",
       " 'have my fire',\n",
       " 'brain a and',\n",
       " 'my have are']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_new_sent = [item for item in unique_new_sent if len(item) <= 14 and len(item) > 0]\n",
    "short_new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e5982de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accept my darker',\n",
       " 'darker brown resembling',\n",
       " 'they darker brown',\n",
       " 'changed it. darker',\n",
       " 'accept eyes are',\n",
       " 'quenched answers same',\n",
       " 'shrouded fear things',\n",
       " 'answers i quenched',\n",
       " 'i changed answers',\n",
       " 'brain a changed',\n",
       " 'changed into fear',\n",
       " 'it. fire changed.',\n",
       " 'resembling answers eyes',\n",
       " 'same accept and',\n",
       " 'little bit mirror',\n",
       " 'changed eyes fire',\n",
       " 'it. darker brown',\n",
       " 'same thirst fear',\n",
       " 'won’t fire shrouded',\n",
       " 'with out darker',\n",
       " 'fire changed. look',\n",
       " 'but changed the',\n",
       " 'won’t they shrouded']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_new_sent = [item for item in unique_new_sent if len(item) > 14]\n",
    "long_new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f966ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear my look\n",
      "darker brown resembling\n",
      "won’t my look\n",
      "i changed answers\n",
      "i won’t fear\n",
      "fire changed. look\n",
      "changed. and a\n",
      "won’t fire shrouded\n",
      "accept bit it\n",
      "same accept and\n",
      "a out little\n",
      "changed into fear\n",
      "i with brain\n",
      "it. darker brown\n",
      "fear my look\n",
      "i changed answers\n",
      "won’t they but\n",
      "accept my darker\n",
      "my have are\n",
      "i changed answers\n"
     ]
    }
   ],
   "source": [
    "#final \n",
    "for i in range(10):\n",
    "    print(random.choice(short_new_sent))\n",
    "    print(random.choice(long_new_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd984d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
